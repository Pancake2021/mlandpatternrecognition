# Шпаргалка по лабораторной работе №1
## Введение и краткая теория

В лабораторной работе моделируются нормально распределённые двумерные случайные векторы и бинарные случайные векторы, проводится оценка параметров распределений, вычисляются расстояния между распределениями и все результаты фиксируются как в файлах, так и отчёте[web:22][web:23].

Нормальное распределение описывает множество случайных процессов (например, рост людей, шум измерений) и является ключевым инструментом статистики. Для двумерных векторов классическое нормальное распределение задаётся матожиданием \( \mu \) и матрицей ковариации \( \Sigma \):

\[
f(\mathbf{x}) = \frac{1}{2\pi|\Sigma|^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x} - \mu)^T\Sigma^{-1}(\mathbf{x} - \mu)\right)
\]
[web:22][web:23]

Бинарные случайные вектора моделируются как независимые координаты, например, с вероятностью появления единицы \( p \) (обычно 0.3)[file:1].

---

## Контрольные вопросы

### 1. Определения:
- **Плотность вероятности** — функция, задающая вероятность появления конкретного значения случайной величины[web:22].
- **Ковариация** — мера совместного отклонения двух случайных величин:
  \[
  \mathrm{Cov}(X,Y) = E[(X - E[X])(Y - E[Y])]
  \]
- **Корреляция** — нормированная ковариация:
  \[
  \rho_{X,Y} = \frac{\mathrm{Cov}(X,Y)}{\sigma_X \sigma_Y}
  \]
- **Параметры нормального распределения** — математическое ожидание \( \mu \) и дисперсия (или в многомерном случае, матрица ковариации) \( \Sigma \)[web:22][web:23].

### 2. Алгоритм моделирования нормально распределённого случайного вектора
- Используется стандартная функция генерации:  
  `numpy.random.multivariate_normal(mean, cov, N)`  
  где mean — вектор ожиданий, cov — ковариационная матрица, N — размер выборки.

### 3. Матрица линейного преобразования
- Для моделирования:  
  Любой двумерный нормальный вектор можно получить линейным преобразованием стандартных нормально распределённых с помощью матрицы хола или квадратного корня из ковариационной[web:22][web:23].  
  \[
  \mathbf{x} = A\mathbf{z} + \mu
  \]
  где \( \mathbf{z} \) — стандартный нормальный вектор, \( A \) — матрица удовлетворяющая \( AA^T = \Sigma \).

### 4. Оценка параметров нормального закона
- Оценки по выборке:
  \[
  \hat{\mu} = \frac{1}{N} \sum_{i=1}^N x_i
  \]
  \[
  \hat{\Sigma} = \frac{1}{N-1} \sum_{i=1}^N (x_i - \hat{\mu})(x_i - \hat{\mu})^T
  \]
- Рекуррентная формула для среднего (по новой точке):
  \[
  \mu_{n+1} = \mu_n + \frac{x_{n+1} - \mu_n}{n+1}
  \]

### 5. Меры близости нормальных распределений
- **Расстояние Махаланобиса**:
  \[
  D_M(\mathbf{x},\mu) = \sqrt{(\mathbf{x}-\mu)^T\Sigma^{-1}(\mathbf{x}-\mu)}
  \]
- **Расстояние Бхатачария**:
  \[
  D_B = \frac{1}{8} (\mu_1-\mu_2)^T \Sigma^{-1} (\mu_1-\mu_2) + \frac{1}{2} \ln \left(\frac{|\Sigma|}{\sqrt{|\Sigma_1| |\Sigma_2|}}\right)
  \]

### 6. Инвариантность расстояний к линейным преобразованиям
- Махаланобис и Бхатачария сохраняют значения при любых невырожденных линейных преобразованиях данных, эллиптических распределениях (масштабирование, повороты векторов)[web:22][web:23].

### 7. Характер линейного преобразования для инвариантности евклидова расстояния
- Инвариантность достигается преобразованием через ортогональную (или ортонормированную) матрицу — вращение, отражение, т.е. преобразования не изменяющие внутренние расстояния.

### 8. Алгоритм моделирования бинарного случайного вектора с независимыми координатами
- Генерировать каждую компоненты независимо с вероятностью \( p \):  
  `numpy.random.binomial(1, p, size)`

### 9. Структура прикладной программы на языке Python
- **Главные части**:
    - data_generation.py — генерация данных.
    - analysis.py — расчёт оценок и расстояний.
    - report.py — визуализация и генерация отчёта.
    - main.py — запуск лабораторной.
    - data/ — файлы результатов.
    - reports/ — генерация финального отчёта в формате Markdown.

---

## Результаты лабораторной
- Получены выборки нормальных и бинарных векторов.
- Проведены вычисления параметров, построены графики распределения, рассчитаны меры близости.
- Все данные сохранены в `.npy`, графики — в `.png`, отчёт — в Markdown.

---

## Формулы

- **Плотность нормального распределения**:  
  \[
  f(x) = \frac{1}{\sigma \sqrt{2\pi}} \exp \left( -\frac{(x-\mu)^2}{2\sigma^2} \right )
  \]
- **Математическое ожидание**:  
  \[
  \mu = E[X] = \sum x_i p_i \text{ } \text{(или интеграл по x)}
  \]
- **Дисперсия**:  
  \[
  \sigma^2 = E[(X-\mu)^2]
  \]
- **Ковариация**:  
  \[
  \mathrm{Cov}(X,Y) = E[(X-\mu_X)(Y-\mu_Y)]
  \]
- **Корреляция**:  
  \[
  \rho_{XY} = \frac{\mathrm{Cov}(X,Y)}{\sigma_X \sigma_Y}
  \]
- **Махаланобис**:  
  см. выше п.5
- **Бхатачария**:
  см. выше п.5

---

## Практическое объяснение
- Моделирование нормально распределённого вектора — основа математической статистики, часто применяется в машинном обучении и обработке данных.
- Все ключевые шаги (генерация, анализ, отчёт) автоматизированы и реализованы через прикладной проект в Python.

---

## Как отвечать на защите
1. Объяснить, как моделируются точки, как строятся выборки.
2. Описать, как оцениваются параметры (среднее и ковариация).
3. Продемонстрировать формулы, показать их смысл.
4. Объяснить смысл расстояний между распределениями.
5. Показать структуру программы и результат отчёта с файлами.

---

**Используйте этот md-файл как шпаргалку на защите: сначала объясняйте теорию, потом практику, результат и формулы!**[web:22][web:23][file:1]

